{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUPQQ-jlMkUd"
      },
      "source": [
        "# Enhancing Customer Support with Generative AI: Applying RAG using CrateDB and LangChain\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) combines a retrieval system, which fetches\n",
        "relevant documents, with a generative model, allowing it to incorporate external\n",
        "knowledge for more accurate and informed responses.\n",
        "\n",
        "It is particularly effective for tasks like question answering, customer support,\n",
        "and any application where referencing external data can enhance the quality of the\n",
        "output.\n",
        "\n",
        "This notebook illustrates the RAG implementation of a customer support scenario.\n",
        "The corresponding dataset is based on a collection of customer support interactions\n",
        "from Twitter related to Microsoft products or services.\n",
        "\n",
        "It is derived from the modern corpus of tweets and replies published on Kaggle,\n",
        "called [Customer Support on Twitter].\n",
        "\n",
        "[Customer Support on Twitter]: https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe-5yxFDMl0S"
      },
      "source": [
        "## What is CrateDB?\n",
        "\n",
        "CrateDB is an open-source, distributed, and scalable SQL analytics database for storing and analyzing massive amounts of data in near real-time, even with complex queries. It is wire-compatible to PostgreSQL, based on Lucene, and inherits the shared-nothing distribution layer of Elasticsearch.\n",
        "\n",
        "Combining RAG with CrateDB's vector store support provides a powerful framework for building sophisticated AI applications. CrateDB can store and manage the vector representations of data, which the RAG retrieval system can then utilize to fetch relevant information. Using vector search, CrateDB can quickly identify the most similar items in a large dataset based on their vector representations.\n",
        "\n",
        "\n",
        "This notebook shows how to use the CrateDB vector store functionality to create a retrieval augmented generation (RAG) pipeline. To implement RAG we use the Python client driver for CrateDB and vector store support in LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFFD7pRwe8m"
      },
      "source": [
        "## What is LangChain?\n",
        "\n",
        "LangChain is an open-source Python library designed to facilitate the creation and deployment of language model chains, particularly in the context of Generative AI. It provides tools for integrating various components of language models, such as retrieval systems, transformers, and custom processing steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE-UtZJnMs2q"
      },
      "source": [
        "## Getting Started\n",
        "CrateDB supports storing vectors since version 5.5. You can leverage the fully managed service of CrateDB Cloud, or install CrateDB on your own, for example using Docker.\n",
        "\n",
        "```shell\n",
        "docker run --publish 4200:4200 --publish 5432:5432 --pull=always crate:latest -Cdiscovery.type=single-node\n",
        "```\n",
        "\n",
        "## Setup\n",
        "\n",
        "Install required Python packages, and import Python modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RJyP1GEXNHUy",
        "outputId": "72c200ce-a75a-4cd0-bb10-d6dfe27541d8",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22))\n",
            "  Cloning https://github.com/crate-workbench/langchain.git (to revision cratedb) to /tmp/pip-install-m61i2o11/langchain_6b3ea58cfef541429114760ab796f8a5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/crate-workbench/langchain.git /tmp/pip-install-m61i2o11/langchain_6b3ea58cfef541429114760ab796f8a5\n",
            "  Resolved https://github.com/crate-workbench/langchain.git to commit 4efd446fc7bffe9ce025d3d07a4a94ef7d8e3810\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain-community@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/community (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 23))\n",
            "  Cloning https://github.com/crate-workbench/langchain.git (to revision cratedb) to /tmp/pip-install-m61i2o11/langchain-community_6be1f81cdd0a476c9577923481a72693\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/crate-workbench/langchain.git /tmp/pip-install-m61i2o11/langchain-community_6be1f81cdd0a476c9577923481a72693\n",
            "  Resolved https://github.com/crate-workbench/langchain.git to commit 4efd446fc7bffe9ce025d3d07a4a94ef7d8e3810\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting crash (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 2))\n",
            "  Downloading crash-0.31.5-py2.py3-none-any.whl (37 kB)\n",
            "Collecting crate[sqlalchemy]==0.35.2 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 3))\n",
            "  Downloading crate-0.35.2-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cratedb-toolkit==0.0.10 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4))\n",
            "  Downloading cratedb_toolkit-0.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai==0.0.6 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading langchain_openai-0.0.6-py3-none-any.whl (29 kB)\n",
            "Collecting pueblo[cli,nlp]>=0.0.7 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9))\n",
            "  Downloading pueblo-0.0.9-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 10)) (2.7.1)\n",
            "Collecting pypdf<5 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 11))\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv<2 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 12))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests<3 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 13)) (2.31.0)\n",
            "Collecting requests-cache<2 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 14))\n",
            "  Downloading requests_cache-1.2.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy==2.* in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 15)) (2.0.30)\n",
            "Collecting unstructured<0.12 (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading unstructured-0.11.8-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.52.0)\n",
            "Collecting langchain-google-vertexai (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 18))\n",
            "  Downloading langchain_google_vertexai-1.0.4-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2.2 in /usr/local/lib/python3.10/dist-packages (from crate[sqlalchemy]==0.35.2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 3)) (2.0.7)\n",
            "Collecting verlib2==0.2.0 (from crate[sqlalchemy]==0.35.2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 3))\n",
            "  Downloading verlib2-0.2.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting geojson<4,>=2.5.0 (from crate[sqlalchemy]==0.35.2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 3))\n",
            "  Downloading geojson-3.1.0-py3-none-any.whl (15 kB)\n",
            "Collecting boltons<25 (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4))\n",
            "  Downloading boltons-24.0.0-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.7/191.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9 in /usr/local/lib/python3.10/dist-packages (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4)) (8.1.7)\n",
            "Collecting click-aliases<2,>=1.0.4 (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4))\n",
            "  Downloading click_aliases-1.0.4-py3-none-any.whl (3.2 kB)\n",
            "Collecting colorama<1 (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting colorlog (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4))\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: python-slugify<9 in /usr/local/lib/python3.10/dist-packages (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4)) (8.0.4)\n",
            "Collecting sqlparse<0.5 (from cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4))\n",
            "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8)) (1.25.2)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading openai-1.30.5-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy==2.*->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 15)) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy==2.*->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 15)) (3.0.3)\n",
            "Requirement already satisfied: Pygments<3,>=2.4 in /usr/local/lib/python3.10/dist-packages (from crash->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 2)) (2.16.1)\n",
            "Requirement already satisfied: platformdirs<5 in /usr/local/lib/python3.10/dist-packages (from crash->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 2)) (4.2.2)\n",
            "Requirement already satisfied: prompt-toolkit<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from crash->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 2)) (3.0.43)\n",
            "Requirement already satisfied: tabulate<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from crash->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 2)) (0.9.0)\n",
            "Collecting contextlib-chdir (from pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9))\n",
            "  Downloading contextlib_chdir-1.0.2-py3-none-any.whl (2.2 kB)\n",
            "Requirement already satisfied: aiohttp<3.10 in /usr/local/lib/python3.10/dist-packages (from pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9)) (3.9.5)\n",
            "Collecting langchain (from pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9))\n",
            "  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 10)) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 13)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 13)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 13)) (2024.2.2)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 14)) (23.2.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 14))\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache<2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 14))\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (5.2.0)\n",
            "Collecting filetype (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (3.8.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (4.12.3)\n",
            "Collecting emoji (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting python-iso639 (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading rapidfuzz-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting unstructured-client (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (1.14.1)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.0.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (0.16)\n",
            "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17))\n",
            "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22)) (6.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22)) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22))\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22)) (8.3.0)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10->pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10->pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10->pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10->pueblo[cli,nlp]>=0.0.7->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 9)) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 14)) (1.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.64.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (0.13.0)\n",
            "INFO: pip is looking at multiple versions of google-cloud-storage to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17))\n",
            "  Downloading google_cloud_storage-2.15.0-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (1.5.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.16 (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading langchain_core-0.1.51-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.49-py3-none-any.whl (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.0/303.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.48-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.47-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.43-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.1/289.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-vertexai (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 18))\n",
            "  Downloading langchain_google_vertexai-1.0.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting langchain-core<0.2,>=0.1.16 (from langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading langchain_core-0.1.41-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.39-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.37-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.6/274.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.35-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8)) (3.7.1)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain[cratedb,openai]@ git+https://github.com/crate-workbench/langchain.git@cratedb#subdirectory=libs/langchain->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 22))\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=14.3 (from google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-protobuf<5.0.0.0,>=4.24.0.4 (from langchain-google-vertexai->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 18))\n",
            "  Downloading types_protobuf-4.25.0.20240417-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0,>=2.31.0 (from langchain-google-vertexai->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 18))\n",
            "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl (15 kB)\n",
            "Collecting langchain-google-vertexai (from -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 18))\n",
            "  Downloading langchain_google_vertexai-1.0.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_google_vertexai-1.0.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_google_vertexai-0.1.3-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_google_vertexai-0.1.2-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_google_vertexai-0.1.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_google_vertexai-0.1.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_google_vertexai-0.0.7-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8)) (4.66.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4,>=3.0->crash->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 2)) (0.2.13)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify<9->cratedb-toolkit==0.0.10->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 4)) (1.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8)) (2024.5.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize>=1.4->requests-cache<2->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 14)) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16)) (1.4.2)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured<0.12->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 16))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.6->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 8))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt (line 17)) (0.6.0)\n",
            "Building wheels for collected packages: langchain-community, langchain, langdetect\n",
            "  Building wheel for langchain-community (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langchain-community: filename=langchain_community-0.0.16-py3-none-any.whl size=1625553 sha256=9b1346ca943d905bae2ec4419444e70ffcd96c498495bfb3db8c46945939176b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j5n9vfrs/wheels/e9/56/b0/ae079ca0652e6487344c1aa91c500a869532b84d6b4adfc126\n",
            "  Building wheel for langchain (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langchain: filename=langchain-0.1.4-py3-none-any.whl size=804638 sha256=43e1eec812f3cf758cddd5c0ba0e19a6168bd6e65c329b4dd5a173436ba7636b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j5n9vfrs/wheels/64/c3/a2/de825e18c2e9458e527ddcd0ff73db67db1b5391091f89eed1\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=1b6f35510892641d56be9e0811fe9806fbe0247a0f4f64a1749a7b4defa5a509\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langchain-community langchain langdetect\n",
            "Installing collected packages: filetype, verlib2, url-normalize, types-requests, types-protobuf, sqlparse, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, packaging, ordered-set, mypy-extensions, langdetect, jsonpointer, jsonpath-python, h11, geojson, emoji, contextlib-chdir, colorlog, colorama, click-aliases, cattrs, boltons, backoff, typing-inspect, tiktoken, requests-cache, pueblo, marshmallow, jsonpatch, httpcore, deepdiff, crate, langsmith, httpx, dataclasses-json, crash, unstructured-client, openai, langchain-core, cratedb-toolkit, unstructured, langchain-openai, langchain-community, google-cloud-storage, langchain, langchain-google-vertexai\n",
            "  Attempting uninstall: sqlparse\n",
            "    Found existing installation: sqlparse 0.5.0\n",
            "    Uninstalling sqlparse-0.5.0:\n",
            "      Successfully uninstalled sqlparse-0.5.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "Successfully installed backoff-2.2.1 boltons-24.0.0 cattrs-23.2.3 click-aliases-1.0.4 colorama-0.4.6 colorlog-6.8.2 contextlib-chdir-1.0.2 crash-0.31.5 crate-0.35.2 cratedb-toolkit-0.0.10 dataclasses-json-0.6.6 deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 geojson-3.1.0 google-cloud-storage-2.14.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.23 langchain-google-vertexai-0.0.7 langchain-openai-0.0.6 langdetect-1.0.9 langsmith-0.0.87 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.30.5 ordered-set-4.1.0 packaging-23.2 pueblo-0.0.9 pypdf-4.2.0 python-dotenv-1.0.1 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.2 requests-cache-1.2.0 sqlparse-0.4.4 tiktoken-0.5.2 types-protobuf-4.25.0.20240417 types-requests-2.32.0.20240523 typing-inspect-0.9.0 unstructured-0.11.8 unstructured-client-0.22.0 url-normalize-1.4.3 verlib2-0.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "b8909ee3b83e4f56bde51c964a130a1b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pip install -r requirements.txt\n",
        "\n",
        "# Note: If you are running in an environment like Google Colab, please use the absolute path of the requirements:\n",
        "!pip install -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VUNjBDrXNNoG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import requests\n",
        "\n",
        "from pueblo.util.environ import getenvpass\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import CrateDBVectorSearch\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxKyWWe1we8n"
      },
      "source": [
        "### Configure database settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3_xLamzwe8o"
      },
      "source": [
        "This notebook will connect to a CrateDB server instance running on localhost. You can start a sandbox instance on your workstation by running [CrateDB using Docker]. Alternatively, you can also connect to a cluster running on [CrateDB Cloud].\n",
        "\n",
        "[CrateDB Cloud]: https://console.cratedb.cloud/\n",
        "[CrateDB using Docker]: https://crate.io/docs/crate/tutorials/en/latest/basic/index.html#docker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "08npVA5_we8o"
      },
      "outputs": [],
      "source": [
        "# Define the connection string to running CrateDB instance.\n",
        "CONNECTION_STRING = os.environ.get(\n",
        "    \"CRATEDB_CONNECTION_STRING\",\n",
        "    \"crate://admin:JwX1kClz,8Ly5fwqZ.BM1h1b@moccasin-bail-prestor-organa.eks1.eu-west-1.aws.cratedb.net/?ssl=true&schema=notebook\",#?schema=openai\n",
        ")\n",
        "\n",
        "# Connect to CrateDB Cloud.\n",
        "# CONNECTION_STRING = os.environ.get(\n",
        "#     \"CRATEDB_CONNECTION_STRING\",\n",
        "#     \"crate://username:password@hostname/?ssl=true&schema=notebook\",\n",
        "# )\n",
        "\n",
        "# Define the store collection to use for this notebook session.\n",
        "COLLECTION_NAME = \"customer_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxJ4poZUwe8o"
      },
      "source": [
        "## Inspect the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VxrG2iswe8p"
      },
      "source": [
        "To illustrate the dataset the next code snippets load dataset into a Pandas DataFrame, display the first few rows\n",
        "and show basic information such as the number of entries, column names, data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DiaLpX30we8p",
        "outputId": "f2d64ba8-4488-4ec0-82fb-bbb732099cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tweet_id       author_id  inbound                      created_at  \\\n",
              "0      2301          116231     True  Tue Oct 31 20:22:23 +0000 2017   \n",
              "1     11879  MicrosoftHelps    False  Wed Nov 01 08:30:56 +0000 2017   \n",
              "2     11881  MicrosoftHelps    False  Thu Oct 26 20:01:31 +0000 2017   \n",
              "3     11890          118332     True  Thu Oct 26 17:29:03 +0000 2017   \n",
              "4     11912  MicrosoftHelps    False  Wed Nov 01 19:12:00 +0000 2017   \n",
              "\n",
              "                                                text response_tweet_id  \\\n",
              "0  @MicrosoftHelps Please get back to me immediat...              2299   \n",
              "1  @118331 Great! We're glad that the issue was r...               NaN   \n",
              "2  @118331 Thank you for the info. Since the driv...             11878   \n",
              "3  @MicrosoftHelps How can i deactivate the Built...             11889   \n",
              "4  @118337 Thank you for the update. We encourage...               NaN   \n",
              "\n",
              "   in_response_to_tweet_id  \n",
              "0                   2306.0  \n",
              "1                  11877.0  \n",
              "2                  11882.0  \n",
              "3                      NaN  \n",
              "4                  11911.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b47aa05f-05ee-461a-98ae-07a46eb1cfd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2301</td>\n",
              "      <td>116231</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 20:22:23 +0000 2017</td>\n",
              "      <td>@MicrosoftHelps Please get back to me immediat...</td>\n",
              "      <td>2299</td>\n",
              "      <td>2306.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11879</td>\n",
              "      <td>MicrosoftHelps</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 01 08:30:56 +0000 2017</td>\n",
              "      <td>@118331 Great! We're glad that the issue was r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11877.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11881</td>\n",
              "      <td>MicrosoftHelps</td>\n",
              "      <td>False</td>\n",
              "      <td>Thu Oct 26 20:01:31 +0000 2017</td>\n",
              "      <td>@118331 Thank you for the info. Since the driv...</td>\n",
              "      <td>11878</td>\n",
              "      <td>11882.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11890</td>\n",
              "      <td>118332</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Oct 26 17:29:03 +0000 2017</td>\n",
              "      <td>@MicrosoftHelps How can i deactivate the Built...</td>\n",
              "      <td>11889</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11912</td>\n",
              "      <td>MicrosoftHelps</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 01 19:12:00 +0000 2017</td>\n",
              "      <td>@118337 Thank you for the update. We encourage...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11911.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b47aa05f-05ee-461a-98ae-07a46eb1cfd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b47aa05f-05ee-461a-98ae-07a46eb1cfd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b47aa05f-05ee-461a-98ae-07a46eb1cfd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2546964-c1cf-4e0b-a0ae-54be9370b05d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2546964-c1cf-4e0b-a0ae-54be9370b05d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2546964-c1cf-4e0b-a0ae-54be9370b05d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 142,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3981,\n        \"min\": 203,\n        \"max\": 13794,\n        \"num_unique_values\": 142,\n        \"samples\": [\n          11877,\n          13767,\n          12873\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"116231\",\n          \"118605\",\n          \"117762\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inbound\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 141,\n        \"samples\": [\n          \"Mon Oct 30 21:56:00 +0000 2017\",\n          \"Wed Oct 25 03:40:50 +0000 2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 142,\n        \"samples\": [\n          \"@MicrosoftHelps Hey - I'm not entirely sure; it sort of resolved itself. I suspect it might have been either a Windows or Nvidia update but I'm not sure \\ud83e\\udd14\",\n          \"@118889 We got your back, Kyle. Just to clarify, are you getting any error messages when signing into your Microsoft account?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_tweet_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"11903,11904,11901,11905,11906\",\n          \"207\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_response_to_tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3868.1313620319934,\n        \"min\": 203.0,\n        \"max\": 13794.0,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          11908.0,\n          9691.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "url = 'https://github.com/crate/cratedb-datasets/raw/main/machine-learning/fulltext/twitter_support_microsoft.csv'\n",
        "dataset = 'twitter_support.csv'\n",
        "\n",
        "r = requests.get(url)\n",
        "with open(dataset, 'wb') as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.read_csv(dataset)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].loc[43]"
      ],
      "metadata": {
        "id": "98r6A9rV4oxL",
        "outputId": "2cbd378d-2386-4f89-a924-6ac838810c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@118333 Hello, Bill. Let us know on how we can improve our support here: https://t.co/ofGxB7VRWk. Thank you.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i5F9HyARwe8p",
        "outputId": "a35da9cb-88b7-400d-b8d4-11ff2bc30a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 142 entries, 0 to 141\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   tweet_id                 142 non-null    int64  \n",
            " 1   author_id                142 non-null    object \n",
            " 2   inbound                  142 non-null    bool   \n",
            " 3   created_at               142 non-null    object \n",
            " 4   text                     142 non-null    object \n",
            " 5   response_tweet_id        92 non-null     object \n",
            " 6   in_response_to_tweet_id  125 non-null    float64\n",
            "dtypes: bool(1), float64(1), int64(1), object(4)\n",
            "memory usage: 6.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# Display basic information about the DataFrame\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07rtc4oEwe8q"
      },
      "source": [
        "## RAG implementation with OpenAI and CrateDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apuTSVVSwe8q"
      },
      "source": [
        "### Configure OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hh4otiKVwe8q",
        "outputId": "d55bddd8-6d2b-4178-f16e-895ed25cfdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API key:··········\n"
          ]
        }
      ],
      "source": [
        "getenvpass(\"OPENAI_API_KEY\", prompt=\"OpenAI API key:\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YCbatCrg0a1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd2BLNlReU01"
      },
      "source": [
        "### Create embeddings from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6Po5rpReNuhn"
      },
      "outputs": [],
      "source": [
        "loader = CSVLoader(file_path=dataset, encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nWl5RSPjPgGv"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "store = CrateDBVectorSearch.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=data,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    connection_string=CONNECTION_STRING,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9H8fXdKwe8q"
      },
      "source": [
        "We use `CSVLoader` class to load support tickets from Twitter. The next step initializes a vector search store in CrateDB using embeddings generated by an OpenAI model. This will create a table that stores the embeddings with the name of the collection. It is important to make sure the collection name is unique and that you have the permission to create a table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XnNZHI6ajaS"
      },
      "source": [
        "### Find relevant context using similarity search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-LZ3IRDwe8r"
      },
      "source": [
        "The following step performs a similarity search against a collection of documents based on the given question. The search uses Eucledian distance to find similar vectors and compute the score. This returns a set of documents (`docs_with_score`) along with their corresponding similarity scores.\n",
        "\n",
        "The code then iterates over these results, and for each document (doc), it adds the content to the list of relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VjLeMkwMagOf"
      },
      "outputs": [],
      "source": [
        "def return_documents(store, question):\n",
        "    # retrieve documents similar to user question\n",
        "    docs_with_score = store.similarity_search_with_score(question)\n",
        "\n",
        "    # extract the page content\n",
        "    documents=[]\n",
        "    for doc, score in docs_with_score:\n",
        "        documents.append(doc.page_content)\n",
        "    return documents\n",
        "\n",
        "documents = return_documents(store, my_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j94BF-3e1Je"
      },
      "source": [
        "### Augment system prompt and query LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_oECs29we8r"
      },
      "source": [
        "In the final step we create an interactive chatbot scenario where GPT-3.5-turbo serves as a customer support assistant, using a preprocessed set of documents as its knowledge base to answer questions about Microsoft products and services. This context represents the information the AI has available to answer customer questions. A `system_prompt` is then constructed, instructing the AI that it is a customer support expert specializing in Microsoft products and services. The prompt also specifies that if the answer to a question isn't in the provided documents, the system should respond with \"I don't know.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WBRAjncxwe8r"
      },
      "outputs": [],
      "source": [
        "def create_prompt(documents):\n",
        "    context = '---\\n'.join(documents)\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "    You are customer support expert and get questions about Microsoft products and services.\n",
        "    To answer question use the information from the context. Remove new line characters from the answer.\n",
        "    If you don't find the relevant information in the context, say \"I don't know\".\n",
        "\n",
        "    Context:\n",
        "    {context}\"\"\"\n",
        "\n",
        "    return system_prompt\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IEuq9r2EaqUz"
      },
      "outputs": [],
      "source": [
        "system_prompt = create_prompt(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Function (DM)"
      ],
      "metadata": {
        "id": "ZhCPDqXl2mDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_New(question):\n",
        "    documents=return_documents(store, question)\n",
        "    context = '---\\n'.join(documents)\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "    You are customer support expert and get questions about Microsoft products and services.\n",
        "    To answer question use the information from the context. Remove new line characters from the answer.\n",
        "    If you don't find the relevant information in the context, say \"I don't know\".\n",
        "\n",
        "    Context:\n",
        "    {context}\"\"\"\n",
        "\n",
        "    return system_prompt"
      ],
      "metadata": {
        "id": "x-JAw5Di2okZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkAPZ55RZQ09"
      },
      "source": [
        "### Ask question\n",
        "Let's define our question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "InhR73isZJCB"
      },
      "outputs": [],
      "source": [
        "my_question = \"How to update shipping address on existing order in Microsoft Store?\"\n",
        "\n",
        "# Alternative question.\n",
        "#my_question = \"I can not make purchase on Xbox for fifa points, what to do?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sntyFqzCwe8r"
      },
      "source": [
        "To answer the question we need an interactive chatbot scenario where GPT-3.5 or another LLM serves as a customer support assistant, using a given set of documents and system prompt:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = openai.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
        "                                               messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "                                                         {\"role\": \"user\", \"content\": my_question}])"
      ],
      "metadata": {
        "id": "AkyJ_IEs2ZUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MnHo6dJwe8r"
      },
      "source": [
        "Finally, to access the content response message generated by the OpenAI model in the context of a chat conversation we need to call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "aQnmpCIZa13L",
        "outputId": "68993c08-42e6-4794-f5c0-6a6b4ed63256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To resolve the issue with purchasing FIFA points on the Xbox One store, you can reach out to @MicrosoftHelps on Twitter for assistance. They should be able to help you with your transaction.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Call (DM)"
      ],
      "metadata": {
        "id": "wW_2lp3g3Ki8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_question=input('Tell me what you are thinking: ')\n",
        "\n",
        "chat_completion = openai.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
        "                                               messages=[{\"role\": \"system\", \"content\": create_prompt_New(my_question)},\n",
        "                                                         {\"role\": \"user\", \"content\": my_question}])\n",
        "\n",
        "print('\\n',chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "r0Cnz6it4AmW",
        "outputId": "ca60dcf3-7f54-4ae6-eda4-3ce40498eaca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me what you are thinking: How can i change my password?\n",
            "\n",
            " To change your password, you can try resetting it using the following link provided by Microsoft Support: https://t.co/JpnONEeZuA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChpsS_aQwe8s"
      },
      "source": [
        "## CrateDB &#129505; OpenSource\n",
        "\n",
        "In the second part of this notebook we build a Retrieval-Augmented Generation (RAG) system using CrateDB with Jina AI and the Llama open-source models.\n",
        "\n",
        "### Configure Jina AI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyA-mHsdwe8s"
      },
      "source": [
        "Jina AI embeddings on Hugging Face are a suite of open-source models designed for encoding text data into high-dimensional vectors, which can be used in various natural language processing tasks such as semantic search, text classification, and clustering. These embeddings utilize the BERT architecture and are specially tuned for longer sequence lengths up to 8192 tokens, which is notably higher than the standard BERT model's capacity.\n",
        "\n",
        "To use Jina AI embeddings you need a Jina AI API key which can be easily obtained once you sign up for an account on the Jina AI website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5hD7rxcwe8s"
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import JinaEmbeddings\n",
        "\n",
        "getenvpass(\"JINA_API_KEY\", prompt=\"Jina API key:\")\n",
        "embeddings = JinaEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQquxEcFwe8s"
      },
      "source": [
        "### Initialize new embedding store\n",
        "\n",
        "The next step initializes a vector search store in CrateDB using embeddings generated by Jina AI models and returns relevant documents using similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veILbcYWwe8s"
      },
      "outputs": [],
      "source": [
        "CONNECTION_STRING = os.environ.get(\n",
        "    \"CRATEDB_CONNECTION_STRING\",\n",
        "    \"crate://crate@localhost/jina\",\n",
        ")\n",
        "\n",
        "COLLECTION_NAME = \"customer_data_jina\"\n",
        "\n",
        "store = CrateDBVectorSearch.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=data,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    connection_string=CONNECTION_STRING,\n",
        ")\n",
        "documents = return_documents(store, my_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iMhhJw6we8s"
      },
      "source": [
        "### Connect to a local LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4mr5bAewe8v"
      },
      "source": [
        "One of the easiest ways to connect to a local LLM is to download one of the models from the [Llamafile repository](https://github.com/Mozilla-Ocho/llamafile#llamafile) and run it locally. Upon initiating the llamafile, it not only sets up a web-based user interface for chatting at the local address http://127.0.0.1:8080/, but it also offers an endpoint for chat completions that is compatible with the OpenAI API.\n",
        "\n",
        "In this example, we use the Phi-2 model that is about 2GB in size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dj8yU8gwe8w"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# An API key is not required!\n",
        "client = OpenAI(\n",
        "    base_url=\"http://localhost:8080/v1\",\n",
        "    api_key = \"sk-no-key-required\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOB9s0Chwe8w"
      },
      "source": [
        "Finally, we create a system prompt using the previously defined template and instantiate a client to interact with the \"LLaMA_CPP\" model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX-qTpL0we8w"
      },
      "outputs": [],
      "source": [
        "system_prompt = create_prompt(documents)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"LLaMA_CPP\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": my_question}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scEYglUmwe8w"
      },
      "source": [
        "After completion, we extract the response message generated by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx_2AnaMwe8w"
      },
      "outputs": [],
      "source": [
        "completion.choices[0].message.content"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}